{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "undefined-concert",
   "metadata": {},
   "source": [
    "# Tensor\n",
    "\n",
    "Tensor是PyTorch核心的数据结构，用于构建矩阵、多维数组等。Tensor不仅为模型编码了输入输出的数据形式，也编码了模型的自身参数。Tensor的特点总结如下：\n",
    "- 支持GPU、TPU加速\n",
    "- 支持自动求导\n",
    "- 可以与`np.ndarray`实现快速转换，不改变内存空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upper-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-identifier",
   "metadata": {},
   "source": [
    "## 1. 创建Tensor\n",
    "\n",
    "- 从列表创建\n",
    "- 从`np.ndarray`创建\n",
    "- 从其他的tensor创建\n",
    "- 根据形状创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "external-heart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# 从列表创建tensor\n",
    "data = [[1,2,3], [2,3,4]]\n",
    "data_tensor = torch.tensor(data)\n",
    "print(data_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "little-apache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# 从np.ndarray创建tensor\n",
    "data_np = np.array(data) # np.array同样可以从列表构建数组\n",
    "data_tensor = torch.from_numpy(data_np)\n",
    "print(data_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-string",
   "metadata": {},
   "source": [
    "当从其他的tensor来创建新的tensor时，若非特别指定，则保留原tensor的形状、数据类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "competent-montana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "data_ones = torch.ones_like(data_tensor)\n",
    "print(data_ones)\n",
    "print(data_ones.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "medieval-green",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1320, 0.7394, 0.7742],\n",
      "        [0.4972, 0.0305, 0.2730]])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "data_rand = torch.rand_like(data_tensor, dtype = torch.float)\n",
    "print(data_rand)\n",
    "print(data_rand.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "global-colorado",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"check_uniform_bounds\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dd3454d9be76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 若使用like函数来生成与原tensor数据类型冲突的tensor，必须指定dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_rand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: \"check_uniform_bounds\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "# 若使用like函数来生成与原tensor数据类型冲突的tensor，必须指定dtype\n",
    "data_rand = torch.rand_like(data_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-personality",
   "metadata": {},
   "source": [
    "根据形状来创建tensor，常用的有以下：\n",
    "- `torch.ones(shape)`\n",
    "- `torch.zeros(shape)`\n",
    "- `torch.rand(shape)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pressed-terror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "data_Zeros: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "data_rand: \n",
      " tensor([[0.5147, 0.6115, 0.0438],\n",
      "        [0.9879, 0.6100, 0.3390]])\n"
     ]
    }
   ],
   "source": [
    "# 根据形状创建tensor\n",
    "shape = (2, 3) # 形状用元组表示\n",
    "\n",
    "data_ones = torch.ones(shape)\n",
    "data_zeros = torch.zeros(shape)\n",
    "data_rand = torch.rand(shape)\n",
    "\n",
    "print(f'Ones tensor: \\n {data_ones}')\n",
    "print(f'data_Zeros: \\n {data_zeros}')\n",
    "print(f'data_rand: \\n {data_rand}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-marina",
   "metadata": {},
   "source": [
    "## Tensor属性（attribute）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fancy-colonial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.Size([2, 3])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(data_rand.dtype)\n",
    "print(data_rand.shape)\n",
    "print(data_rand.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-thompson",
   "metadata": {},
   "source": [
    "## Tensor opration\n",
    "\n",
    "有关Tensor的操作，完整列表可见官方文档：https://pytorch.org/docs/stable/torch.html\n",
    "\n",
    "Tensor默认被创建在CPU上，若需要将它转移到GPU上，可以使用`to`函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "convertible-friendly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "data_rand = torch.rand(3, 4).to('cuda') if torch.cuda.is_available() else torch.rand(3, 4).to('cpu')\n",
    "\n",
    "print(data_rand.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-parliament",
   "metadata": {},
   "source": [
    "Tensor和numpy数组一样支持切片操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "optimum-baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "data_ones = torch.ones(4, 4).to('cuda')\n",
    "\n",
    "print(data_ones[0])\n",
    "print(data_ones[:1])\n",
    "print(data_ones[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sonic-dividend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 2.],\n",
      "        [1., 1., 1., 2.],\n",
      "        [1., 1., 1., 2.],\n",
      "        [1., 1., 1., 2.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "data_ones[:, -1] = 2\n",
    "print(data_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-cooper",
   "metadata": {},
   "source": [
    "tensor支持cat拼接操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "single-orientation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 2.],\n",
      "        [1., 1., 1., 2.],\n",
      "        [1., 1., 1., 2.],\n",
      "        [1., 1., 1., 2.],\n",
      "        [1., 1., 1., 2.],\n",
      "        [1., 1., 1., 2.],\n",
      "        [1., 1., 1., 2.],\n",
      "        [1., 1., 1., 2.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "data_cat = torch.cat([data_ones, data_ones])\n",
    "print(data_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "opponent-cattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 2., 1., 1., 1., 2.],\n",
      "        [1., 1., 1., 2., 1., 1., 1., 2.],\n",
      "        [1., 1., 1., 2., 1., 1., 1., 2.],\n",
      "        [1., 1., 1., 2., 1., 1., 1., 2.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "data_cat = torch.cat([data_ones, data_ones], dim=1)\n",
    "print(data_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-entrance",
   "metadata": {},
   "source": [
    "矩阵乘法：\n",
    "- @\n",
    "- matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "czech-channel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True) tensor(True)\n",
      "tensor([[4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out = y3)\n",
    "\n",
    "print(y1.all() == y2.all(), y1.all() == y3.all())\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-variable",
   "metadata": {},
   "source": [
    "矩阵逐元素相乘：\n",
    "- *\n",
    "- mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "decent-completion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True) tensor(True)\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out = z3)\n",
    "\n",
    "print(z1.all() == z2.all(), z1.all() == z3.all())\n",
    "print(z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-closure",
   "metadata": {},
   "source": [
    "tensor In-place 操作：\n",
    "\n",
    "在PyTorch中，tensor的In-place操作将直接修改tensor本身，这些操作以`_`后缀为标志：\n",
    "- `x.add_()`\n",
    "- `x.copy_()`\n",
    "- `x.t_()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-score",
   "metadata": {},
   "source": [
    "## Tensor与numpy的互相转换\n",
    "\n",
    "- 将tensor转换为numpy数据：`tensor.numpy()`\n",
    "- 将numpy数据转换为tensor：`torch.from_numpy()`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
